# File Organization Skill — Eval Results

## Eval 1: Repro Script vs. Handler Fix

**Prompt:** "I need to fix a race condition in the websocket handler. I wrote a quick Python script to simulate concurrent connections and reproduce the bug. I also fixed the actual handler. Where does each file go?"

**Expected Output:** The Python repro script is a working artifact → /temporary/. The websocket handler fix is a deliverable → commit in place.

**Relevant Guidance:**
- "Script to reproduce a bug → debug-repro.py (working artifact)" (Line 33)
- "I'm creating this because the user asked for it / it solves the task" → Project tree (Line 11)
- "I'm creating this to help me work — debug, analyze, test an idea" → /temporary/ (Line 12)

**Analysis:**
The skill clearly distinguishes between debugging artifacts ("Script to reproduce a bug") and actual fixes. An agent following the core principle would recognize:
- The Python script's intent: "help me understand/debug" → /temporary/
- The handler fix's intent: "solves the task" → project tree

The guidance is unambiguous. The agent gets the correct answer.

**Rating: PASS**

---

## Eval 2: User-Requested Tests vs. Scratch File

**Prompt:** "User asked me to add unit tests for the payment module. I also created a scratch file to test some regex patterns I needed for the validation logic. Where does each go?"

**Expected Output:** The unit tests are deliverables (user asked for them) → project tree. The regex scratch file is a working artifact → /temporary/.

**Relevant Guidance:**
- "Write unit tests for auth" → auth.test.ts (deliverable) (Line 26)
- "Add user validation with tests" example shows validate.test.ts as deliverable because "User asked for tests" (Line 85)
- "Quick test to verify an assumption → check-behavior.js (working artifact)" (Line 35)

**Analysis:**
The skill explicitly handles this distinction in the "Add user validation with tests" example (Lines 76-85), which directly parallels Eval 2:
- User-requested tests (validate.test.ts) = deliverable
- Scratch working files (scratch-regex-test.js) = working artifact

The key insight is whether **the user asked for** the tests. The skill states this clearly. An agent would correctly identify:
- User explicitly asked for unit tests → deliverable
- Regex pattern scratch file is "to help me work" (testing an assumption) → working artifact

**Potential gap:** The skill doesn't address a borderline case where scratch tests could be mistaken for part of the test suite if the agent isn't careful about the "user asked for" criterion. However, the stated guidance is clear enough.

**Rating: PASS**

---

## Eval 3: Existing Tracked Tests vs. Debug Script

**Prompt:** "I see there's a tests/ directory with existing test files. I also see a file called check-api.sh in the root that I created yesterday to debug an endpoint. What should I do?"

**Expected Output:** Leave the tests/ directory alone — it's an existing tracked test suite. Move check-api.sh to /temporary/ since it's a debug working artifact.

**Relevant Guidance:**
- "Existing files you modified (they're already tracked in git)" — Never working artifacts (Line 108)
- "Test suites the project already has (`tests/`, `__tests__/`, `spec/`)" — Never working artifacts (Line 109)
- "If a file already exists in the git tree, it belongs there. Your job is only to route **new files you create** during your working process." (Line 116)

**Analysis:**
The skill explicitly states that existing tracked files are "NEVER working artifacts" and gives `tests/` as a direct example. For check-api.sh, the intent is clear: debug artifact, not user-requested deliverable.

An agent would correctly identify:
1. tests/ is already tracked → don't touch it
2. check-api.sh intent: "to help me debug" → /temporary/

The guidance is explicit and unambiguous. The agent would get the right answer.

**Rating: PASS**

---

## Eval 4: Generated-but-Committed Migration vs. Analysis Notes

**Prompt:** "I'm working on a database migration task. I generated a migration file using the ORM CLI, and I also wrote an analysis.md exploring different indexing strategies. Where do these go?"

**Expected Output:** The migration file is a deliverable (generated but committed as part of the project) → project tree. The analysis.md is a working artifact → /temporary/.

**Relevant Guidance:**
- "Database migrations are generated but absolutely committed" (Line 94)
- "Migration files (database schema changes)" — Never working artifacts (Line 112)
- "Markdown notes analyzing the codebase → analysis.md (working artifact)" (Line 34)

**Analysis:**
The skill handles this well. It explicitly recognizes that "generated" doesn't mean "working artifact" — migrations are generated by the ORM but belong in the project because they're **part of the deliverable** (schema changes that must be committed).

For the migration file: The skill states directly "Migration files (database schema changes)" as something that is never a working artifact.

For analysis.md: The skill lists "Markdown notes analyzing the codebase → analysis.md (working artifact)" — this directly matches the evaluation scenario.

An agent would correctly identify:
1. Migration file: "the project commits this" + "database schema changes" → project tree
2. analysis.md: "notes analyzing the codebase" + "to help me work" → /temporary/

The guidance is explicit and covers both cases directly.

**Rating: PASS**

---

## Eval 5: Requested Component vs. Debug Render vs. Existing Test Suite

**Prompt:** "I created a new React component as requested, plus a debug-render.jsx to test how it renders in isolation. The project already has a __tests__/ folder. Where does everything go?"

**Expected Output:** The React component is a deliverable → project tree. debug-render.jsx is a working artifact → /temporary/. The __tests__/ folder is existing tracked code — don't touch it.

**Relevant Guidance:**
- "The user asked for it / it solves the task" → Project tree (Line 11)
- "I need this to help me understand, debug, or explore" → /temporary/ (Line 31)
- "Test suites the project already has (`tests/`, `__tests__/`, `spec/`)" — Never working artifacts (Line 109)

**Analysis:**
This eval tests three things:
1. **Requested component:** Clear deliverable intent
2. **Debug render file:** Clearly a working artifact ("test how it renders in isolation" = debugging/exploring)
3. **Existing __tests__/ folder:** Explicitly listed as something to never move

The skill handles all three. The guidance is clear. An agent would get the right answer.

**Rating: PASS**

---

## Eval 6: Git Status Cleanup (Layer 2)

**Prompt:** "Before committing, I ran git status and see: modified src/api/users.ts, new file src/api/users.test.ts (user asked for tests), new file output.log, new file temp-check.py. How do I clean this up?"

**Expected Output:** Commit users.ts (modified existing) and users.test.ts (deliverable). Move output.log and temp-check.py to /temporary/ (working artifacts).

**Relevant Guidance:**
- Layer 2 reactive check (Lines 42-55)
- "Did the user's task require this file? If no → move to /temporary/" (Line 53)
- "Does this file exist in the project already? If yes, you're editing existing code — that's fine, leave it" (Line 54)
- "Is this a new file I created to help myself work? If yes → move to /temporary/" (Line 55)
- Example showing git status cleanup (Lines 57-74) with similar structure

**Analysis:**
The skill provides the Layer 2 reactive framework directly:
1. **modified users.ts:** Already tracked → commit
2. **new users.test.ts:** User asked for tests (stated in prompt) → commit
3. **new output.log:** Created during working process (debug output) → /temporary/
4. **new temp-check.py:** Name itself suggests "to help myself work" + temporary → /temporary/

The example (Lines 57-74) shows the exact scenario structure. The three questions in Layer 2 map directly:
- Q1 (did user ask?): No for output.log and temp-check.py → move
- Q2 (already exists?): No for new files, but users.ts exists → commit users.ts
- Q3 (new artifact?): Yes for output.log and temp-check.py → move

An agent would get the right answer following the Layer 2 framework.

**Rating: PASS**

---

## Summary Assessment

| Eval | Result | Confidence | Notes |
|------|--------|-----------|-------|
| 1 | PASS | High | Clear distinction between debug script and fix |
| 2 | PASS | High | Explicit example matches eval scenario |
| 3 | PASS | High | Existing files explicitly excluded from working artifacts |
| 4 | PASS | High | Migrations explicitly covered; analysis.md directly exemplified |
| 5 | PASS | High | All three elements (new component, debug file, existing suite) handled clearly |
| 6 | PASS | High | Layer 2 framework provides exact decision tree; example mirrors scenario |

## Critical Findings

**All evals achieve PASS.** The skill provides:

1. **Clear intent-based framework** that works across all scenarios
2. **Explicit examples** that map directly to evals 2, 4, 5, and 6
3. **Direct lists** of files that are "NEVER working artifacts," covering edge cases in evals 3 and 5
4. **Layer 2 reactive checks** that handle the git status scenario (eval 6) with a concrete decision tree
5. **Explicit handling of "generated but committed"** files like migrations (eval 4)

The skill successfully distinguishes user-requested deliverables from working artifacts across all cases. Agents following either Layer 1 (proactive) or Layer 2 (reactive) would arrive at correct answers for all six evals.

### Strengths of the Skill

- **Not file-type dependent:** The "intent" approach works for all scenarios without fragile extension-based rules
- **Handles edge cases explicitly:** Migrations, codegen, existing tracked files all explicitly addressed
- **Concrete examples:** Evals 2, 4, 5 are nearly identical to skill examples
- **Dual-layer approach:** Catches mistakes at creation time or before commit

### No Significant Gaps Identified

All three "focus areas" from the prompt are handled well:
- **Eval 2 (user-requested vs. scratch tests):** Clear distinction via "user asked for"
- **Eval 3 (existing tracked files):** Explicit list + general rule about existing files
- **Eval 4 (generated-but-committed):** Direct mention of migrations + intent-based reasoning

